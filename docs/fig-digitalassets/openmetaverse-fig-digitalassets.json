{"data":{"repository":{"discussions":{"totalCount":5,"nodes":[{"id":"D_kwDOI2aWU84AS6v_","category":{"name":"General"},"upvoteCount":1,"updatedAt":"2023-03-13T19:00:12Z","createdAt":"2023-03-13T18:58:35Z","number":6,"title":"GLTF as a arbitrary-binary container format","body":"A GLTF defining arbitrary binary data while having a simple standard JSON interface could look something like this. It could also define 3D scenes and even standard representations of geometry to contain this data.\r\n``` \r\n{\r\n  \"asset\": {\r\n    \"version\": \"2.0\"\r\n  },\r\n  \"buffers\": [\r\n    {\r\n      \"byteLength\": 2048,\r\n      \"uri\": \"metaverse_data.bin\"\r\n    }\r\n  ],\r\n  \"bufferViews\": [\r\n    {\r\n      \"buffer\": 0,\r\n      \"byteOffset\": 0,\r\n      \"byteLength\": 1024,\r\n      \"type\": \"image/png\"\r\n    },\r\n    {\r\n      \"buffer\": 0,\r\n      \"byteOffset\": 1024,\r\n      \"byteLength\": 1024,\r\n      \"type\": \"application/octet-stream\"\r\n    }\r\n  ],\r\n  ```\r\n  In reference to this subject of how GLTF could apply to these goals:\r\n  \r\n    Simple to implement\r\n    Arbitrary binary objects, indexed by hash\r\n    MIME-type metadata on objects\r\n    Reading and remotely fetching individual objects, using direct offsets\r\n    Optional compression\r\n    Optional separate metadata and indices file\r\n    Exporting package-level 'interfaces', to define named exported objects.\r\n","author":{"login":"KooIaIa"},"comments":{"nodes":[]},"labels":{"nodes":[]}},{"id":"D_kwDOI2aWU84AS6nv","category":{"name":"Meetings"},"upvoteCount":1,"updatedAt":"2023-03-13T16:05:05Z","createdAt":"2023-03-13T16:05:05Z","number":5,"title":"Proposed Digital Assets meeting agenda for 2023-03-13","body":"## Meeting Details\r\n\r\n- **Date/Time:** March 13, 2023 @ Monday 12:00 PM ET / 17:00 UTC / 6:00 PM CET\r\n- **Location:** Link should be posted in the `#Digital-assets` text and voice channel on Discord at least 5 days before the meeting.\r\n- **Moderator:** TBA\r\n- **Note Taker** Person\r\n\r\nThe [FIG Digital Assets](https://github.com/Open-MV/fig-digitalassets/tree/main/meetings) repo contains the history past meetings, including a link to the agenda, recording, notes, and resources.\r\n\r\n## Meeting Agenda\r\nDacti Format : [ttps://gist.github.com/LaylBongers/4981bdbc4daa05b790991d37a429c733](https://gist.github.com/LaylBongers/4981bdbc4daa05b790991d37a429c733)\r\n[Github Repo](https://github.com/open-mv-sandbox/dacti) -- [HedgeDoc collab link](https://hedgedoc.openmv.org/6ws4pKM6Rqu7n_EddtbYmg)\r\nPrioritize Database entries: https://lists.openmv.org/g/fig-digitalassets/table?id=37927\r\nDiscuss Oasis 3D as an option\r\nContinue discussion around Wolvic: [Wolvic Github](https://github.com/Igalia/wolvic) [Wolvic Site](https://www.wolvic.com/en/)\r\n\r\n## Outcomes from Discussion topics\r\n\r\n**Discuss outcomes from agenda**\r\n\r\n## Action Items\r\n\r\n**Create actionable items from proposed topics**\r\n\r\n## Items for next week's meeting\r\n**List items that need to be discussed next week**\r\n\r\n## Open Discussion Items\r\n\r\nList any additional items below!","author":{"login":"OBWANDO"},"comments":{"nodes":[]},"labels":{"nodes":[]}},{"id":"D_kwDOI2aWU84AStMv","category":{"name":"Meetings"},"upvoteCount":1,"updatedAt":"2023-02-27T15:12:50Z","createdAt":"2023-02-27T15:12:49Z","number":4,"title":"Proposed Digital Assets meeting agenda for 2023-02-27","body":"## Meeting Details\r\n\r\n- **Date/Time:** February 27, 2023 @ Monday 12:00 PM ET / 17:00 UTC / 6:00 PM CET\r\n- **Location:** Link should be posted in the `#Digital-assets` text and voice channel on Discord at least 5 days before the meeting.\r\n- **Moderator:** TBA\r\n- **Note Taker** Person\r\n\r\nThe [FIG Digital Assets](https://github.com/Open-MV/fig-digitalassets/tree/main/meetings) repo contains the history past meetings, including a link to the agenda, recording, notes, and resources.\r\n\r\n## Meeting Agenda\r\nDacti Format : [ttps://gist.github.com/LaylBongers/4981bdbc4daa05b790991d37a429c733](https://gist.github.com/LaylBongers/4981bdbc4daa05b790991d37a429c733)\r\n[Github Repo](https://github.com/open-mv-sandbox/dacti) -- [HedgeDoc collab link](https://hedgedoc.openmv.org/6ws4pKM6Rqu7n_EddtbYmg)\r\nPrioritize Database entries: https://lists.openmv.org/g/fig-digitalassets/table?id=37927\r\nDiscuss Oasis 3D as an option\r\nContinue discussion around Wolvid: [Wolvic Github](https://github.com/Igalia/wolvic) [Wolvic Site](https://www.wolvic.com/en/)\r\n\r\n## Outcomes from Discussion topics\r\n\r\n**Discuss outcomes from agenda**\r\n\r\n## Action Items\r\n\r\n**Create actionable items from proposed topics**\r\n\r\n## Items for next week's meeting\r\n**List items that need to be discussed next week**\r\n\r\n## Open Discussion Items\r\n\r\nList any additional items below!","author":{"login":"OBWANDO"},"comments":{"nodes":[]},"labels":{"nodes":[]}},{"id":"D_kwDOI2aWU84ASnB6","category":{"name":"Meetings"},"upvoteCount":1,"updatedAt":"2023-02-27T15:13:02Z","createdAt":"2023-02-20T15:43:27Z","number":3,"title":"Digital Assets meeting agenda for 2023-02-20","body":"## Meeting Details\r\n\r\n- **Date/Time:** February 20, 2023 @ Monday 12:00 PM ET / 17:00 UTC / 6:00 PM CET\r\n- **Location:** Link should be posted in the `#Digital-assets` text and voice channel on Discord at least 5 days before the meeting.\r\n- **Moderator:** TBA\r\n- **Note Taker** Person\r\n\r\nThe [FIG Digital Assets](https://github.com/Open-MV/fig-digitalassets/tree/main/meetings) repo contains the history past meetings, including a link to the agenda, recording, notes, and resources.\r\n\r\n## Meeting Agenda\r\nDacti Format : [ttps://gist.github.com/LaylBongers/4981bdbc4daa05b790991d37a429c733](https://gist.github.com/LaylBongers/4981bdbc4daa05b790991d37a429c733)\r\n[Github Repo](https://github.com/open-mv-sandbox/dacti) -- [HedgeDoc collab link](https://hedgedoc.openmv.org/6ws4pKM6Rqu7n_EddtbYmg)\r\nPrioritize Database entries: https://lists.openmv.org/g/fig-digitalassets/table?id=37927\r\nDiscuss Wolvic as an option: [Wolvic Github](https://github.com/Igalia/wolvic) [Wolvic Site](https://www.wolvic.com/en/)\r\n\r\n## Outcomes from Discussion topics\r\n\r\n**Discuss outcomes from agenda**\r\n\r\n## Action Items\r\n\r\n**Create actionable items from proposed topics**\r\n\r\n## Items for next week's meeting\r\n**List items that need to be discussed next week**\r\n\r\n## Open Discussion Items\r\n\r\nList any additional items below!","author":{"login":"OBWANDO"},"comments":{"nodes":[{"id":"DC_kwDOI2aWU84ATSj5","author":{"login":"lyuma"},"body":"I am attaching a snapshot of the table as it was at the end of the meeting:\r\n\r\n[Digital Assets Narrative Feature Table.csv](https://github.com/Open-MV/fig-digitalassets/files/10787320/Digital.Assets.Narrative.Feature.Table.csv)\r\n\r\n<html>\r\n<body>\r\n<!--StartFragment-->\r\n\r\n  | ID | Line# | Feature Synopsis | Priority | Explanation and relation to sentence | Similar Open-Source, Github Ticket URL or Dep / Status | DIscord / Name (Optional) | Updated\r\n-- | -- | -- | -- | -- | -- | -- | -- | --\r\n  |   | 2 | 1 | 3D Model Metadata for compatibility and discovery | 5 | To provide virtual 3D objects, we will need a mechanism to pull metadata down about a 3D model and texture before retrieving the data itself. This will allow us to determine the software and hardware compatibility as well as the conversion requirements to make decisions on the media itself. The metadata should be independent of the actual data file/blob and augment its usage. | https://github.com/open-mv-sandbox/dacti | Royal OBrien | 9:40am\r\n  |   | 3 | 4 | Share valuable goods, objects for users to explore and intercat with in interoperable digital worlds | 1000 | There is no doubt that the Metaverse Standard Forum is moving towards true glTF 2.0 and USD standards as a system for the interchange and interoperability of Digital Assets, see in this regard: https://docs.google.com/presentation/d/1tpKTlp9aVeJGD0E_0yBGuo37omZhGAjWmM1OH8hnsQ8/edit#slide=id.g1437ecae60d_5_338 However, we should not forget that other groups and consortia have already addressed the management of interoperability of digital assets, such as the ISO X3D standard: https://www.web3d.org/x3d4-highlights which in its version 4.0 abandoned XML in favor of a lighter JSON. Oddly enough, this standard has been unfairly snubbed by the worldwide developer community. | https://github.com/KhronosGroup/glTF, https://github.com/PixarAnimationStudios/USD, https://www.web3d.org/x3d4-highlights Status: Needs research for implementation in different places. Who uses it? where? | Vytek#1391 | 9:44am\r\n  |   | 4 | 3 | Access from anywhere and on any device | 10 | Mesh compression is very important, and the Draco compression algorithm often comes immediately to mind. In reality there are different algorithms whose goal is a proper balance between compression and compression/decompression speed. The Italian CNR short algorithm is a benchmark in the scientific literature mediating speed and compression. | https://github.com/cnr-isti-vclab/corto, http://vcg.isti.cnr.it/corto/ Competing types: Which makes more sense to drive energy to https://naver.github.io/egjs-view3d/docs/tutorials/Compression/Meshopt https://google.github.io/draco/ Look at specify in DACTI as a header type. | Vytek#1391 | 9:53am\r\n  |   | 5 | 1 | Dynamically accessible mesh LODs | 6 | With the progress with GLTF and USD, there may also be a need to provide metadata that can point to multiple references of varying LODs for mesh objects that can be dynamically loaded to optimize speed of initial and ongoing load of data to match hardware environment. Devices may need reduced meshes to match capabilities and speed up time to view. (We dont need fifty 100k poly objects running on a mobile device) | Need to make sure we have DACTI support and best practices for device types and number of polys - High end and low end Mobile and PC as primary types | Royal OBrien | 9:59am\r\n  |   | 6 | 1 | Dynamically accessible texture resolutions |   | Create indexed texture metadata for different LOD/MIP levels that can be loaded depending on location and point of view. This will be needed to reduce device and network load overhead for a faster time of view for experiences. It will also enable compatibility for devices that may not need or process high texture resolution due to display capabilities. (We don't need one hundred 4k textures on a mobile device, and if you are far away from an object, you should be loading a 32x32 LOD versus a 4k texture times 50 textures) |   | Royal OBrien | Feb 10\r\n  |   | 7 | 2 | Precompiled Device texture formats |   | Different devices use different texture formats from the source media (jpg/png/tga). As textures are not baked in like applications, we will need to accomodate these extended texture formats so they can be cached and referenced dynamically. These include mobile formats like DDS/S3TC, ETC1, ETC2, ASTC, ATC, PVRTC, DXT1 that would cause greater battery power loss and performance or wait issues. This may not be necessary for desktop formats as they can be dynamically converted on the GPU itself (DXT5, BC6H and BC7). |   | Royal OBrien | Feb 10\r\n  |   | 8 | 2 | Metadata for multichannel texture referencing. |   | Engines have varying levels of support for texture formats. Providing a single texture source with all possible formats wastes network, storage, and CPU usage. These channels can vary and may include one or more elements: Diffuse, Metallic, Roughness, Normal, Displacement, Ambient Occlusion, Opacity, or Emissive. The requesting device should be able to look up the metadata and thread/load the appropriate formats reducing overhead. |   | Royal OBrien | Feb 10\r\n  |   | 9 | 20 | Identify standard skeletal animation format |   | Currently, skeletal animations are stored in FBX, XSI, MA, and others, but we will need a portable format that will be open-source and accessible to all. The standard format should consider all of the current capabilities in these formats and extend the metadata for platform/device awareness and different animation models like Procedural, morph targets, and blended models. | https://github.com/guillaumeblanc/ozz-animation | Royal OBrien | Feb 10\r\n  |   | 10 | 20 | Standardize naming for root and basic identifiable nodes. |   | Objects like avatars, vehicles, and other entities will require a standard set of naming convention to distinguish the major attachment and relationship points. This data will be required to accessorize and allow interopability between content creators, animation artists, riggers and character designers. |   | Royal OBrien | Feb 10\r\n  |   | 11 | 6 | Identify or create standard scene or area description format |   | Each 3D engine has a different format for describing a scene and its coordinate system. Some can use USD or embedded formats. We need to look at what is available and come to a versatile, quickly parsable, and lightweight format that can provide TRS and extended data for different entities, whether mutable or immutable. This would include but is not limited to references to geometry, entities, colliders, prefabs, skybox, scripted code, players, triggers, light entities, portals, and boundaries. Each object class should be clearly defined so the end client can interpret these objects if supported. It is akin to how basic HTML can be used to instruct how to place objects in a 2D window, but the extensible support of CSS and other features is up to the client's implementation. These should always be lightweight and not attached to objects, allowing for hot-reloading and dynamic updates. |   | Royal OBrien | Feb 1\r\n\r\n<!--EndFragment-->\r\n</body>\r\n</html>"}]},"labels":{"nodes":[]}},{"id":"D_kwDOI2aWU84ASar2","category":{"name":"Meetings"},"upvoteCount":1,"updatedAt":"2023-02-20T15:45:57Z","createdAt":"2023-02-06T14:01:19Z","number":2,"title":"Digital Assets meeting agenda for 2023-02-13","body":"## Meeting Details\r\n\r\n- **Date/Time:** February 13, 2023 @ Monday 12:00 PM ET / 17:00 UTC / 6:00 PM CET\r\n- **Location:** Link should be posted in the `#Digital-assets` text and voice channel on Discord at least 5 days before the meeting.\r\n- **Moderator:** TBA\r\n- **Note Taker** Person\r\n\r\nThe [FIG Digital Assets](https://github.com/Open-MV/fig-digitalassets/tree/main/meetings) repo contains the history past meetings, including a link to the agenda, recording, notes, and resources.\r\n\r\n## Meeting Agenda\r\nFirst meeting and operating\r\nFIG charter discussion\r\nDatabase Feature triage\r\n\r\n**Discuss agenda from proposed topics**\r\n\r\n## Outcomes from Discussion topics\r\n\r\n**Discuss outcomes from agenda**\r\n\r\n## Action Items\r\n\r\n**Create actionable items from proposed topics**\r\n\r\n## Items for next week's meeting\r\n**List items that need to be discussed next week**\r\n\r\n## Open Discussion Items\r\n\r\nList any additional items below!","author":{"login":"OBWANDO"},"comments":{"nodes":[{"id":"DC_kwDOI2aWU84ASoNC","author":{"login":"vamman"},"body":"I would like to add the following items to the discussion for the next few weeks on the format being used to transport DAP. We have a tremendous amount of experience on this topic with GenXP and our clients wants/needs. Please leverage our experience on this topic.\r\n\r\nDAP can not exist without a universal format the captures everything that is common with a rendering scene:\r\n\r\n- Begin discussion on use of different formats currently available such as \r\n- Universal Scene Descriptor (USD) as a starting point to support non-destructive digital-asset portability.\r\n- VRML\r\n- Others??\r\n- Render Capture/Injection as a possible R&D topic that allows us to explore where Injection is the best method to satisfy all engines?\r\n- Omniverse: What is it? How does it work? How can we use it?\r\n- Where and how are DAPs stored as a binary? Public depot? How does authorship/ownership/enterprise IP of a DAP work?\r\n\r\nRelevant links:\r\n- UE5.1 integration with USD: https://docs.unrealengine.com/5.1/en-US/universal-scene-description-in-unreal-engine/\r\n- Pixar USD: https://graphics.pixar.com/usd/release/index.html\r\n- NVIDIA USD: https://developer.nvidia.com/usd\r\n- VRML: https://en.wikipedia.org/wiki/VRML"},{"id":"DC_kwDOI2aWU84AS7G2","author":{"login":"aaronfranke"},"body":"I would like to discuss bringing in the GLTF extension standards that OMI has been working on and having the OMF endorse them and/or iterate on them if we discuss any changes.\r\n\r\n* Collider: https://github.com/omigroup/gltf-extensions/tree/main/extensions/2.0/OMI_collider\r\n* Physics body: https://github.com/omigroup/gltf-extensions/tree/main/extensions/2.0/OMI_physics_body\r\n* Spawn point: https://github.com/omigroup/gltf-extensions/tree/main/extensions/2.0/OMI_spawn_point\r\n* Audio: https://github.com/omigroup/gltf-extensions/tree/main/extensions/2.0/KHR_audio\r\n\r\nAll of these build on top of [GLTF](https://github.com/KhronosGroup/glTF), the open 3D model format from Khronos.\r\n\r\nI see above that there is discussion about USD. A lot of open projects are adopting GLTF, but we could support both GLTF and USD if that's desired. These standards I linked above could be ported over to USD if it supports extending with arbitrary data like GLTF does, and then that would provide an easy path to converting between the two."},{"id":"DC_kwDOI2aWU84AS7PP","author":{"login":"LaylBongers"},"body":"I would like to briefly ask people to look at the Dacti package format draft at this point and give feedback.\r\n<https://gist.github.com/LaylBongers/4981bdbc4daa05b790991d37a429c733>"}]},"labels":{"nodes":[]}}]}}}}